#!/usr/bin/env python3
"""
Table Analyzer Servisi
Tablolardan metin yorumlamasÄ± Ã¼retimi (JSON, CSV, Excel desteÄŸi)
"""

import os
import json
import pandas as pd
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from pydantic import BaseModel
import requests
import time
import io

# FastAPI uygulamasÄ±
app = FastAPI(
    title="Table Analyzer Service",
    description="Tablolardan metin yorumlamasÄ± Ã¼reten servis",
    version="1.0.0"
)

# Ortam deÄŸiÅŸkenleri
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
MODEL_NAME = os.getenv("MODEL_NAME", "gemma3:27b")
PORT = int(os.getenv("PORT", 8010))

# Pydantic modelleri
class TableAnalysisRequest(BaseModel):
    table_data: List[Dict[str, Any]]
    language: str = "turkish"  # turkish, english
    output_format: str = "text"  # text, json, markdown

class TableAnalysis(BaseModel):
    title: str
    executive_summary: str
    key_insights: List[str]
    statistical_analysis: str
    trend_analysis: str
    comparative_analysis: str
    correlation_analysis: str
    anomaly_detection: str
    business_implications: str
    strategic_recommendations: List[str]
    risk_assessment: str
    future_projection: str
    detailed_analysis: str

class TableAnalysisResponse(BaseModel):
    success: bool
    analysis: TableAnalysis
    metadata: Dict[str, Any]

# IELTS Vocabulary TÃ¼rkÃ§e Ã‡evirisi ve Ã‡eÅŸitlilik
TURKISH_VOCABULARY = {
    "trend_verbs": {
        "increase": ["artÄ±ÅŸ gÃ¶stermek", "yÃ¼kselmek", "artmak", "Ã§Ä±kmak", "yÃ¼kseliÅŸe geÃ§mek", "ilerlemek"],
        "decrease": ["azalÄ±ÅŸ gÃ¶stermek", "dÃ¼ÅŸmek", "azalmak", "gerilemek", "dÃ¼ÅŸÃ¼ÅŸe geÃ§mek", "kaybetmek"],
        "stable": ["sabit kalmak", "deÄŸiÅŸmemek", "istikrarlÄ± olmak", "duraÄŸan kalmak", "sabitlenmek"],
        "fluctuate": ["dalgalanmak", "deÄŸiÅŸkenlik gÃ¶stermek", "istikrarsÄ±z olmak", "sÃ¼rekli deÄŸiÅŸmek"]
    },
    "intensity_adverbs": {
        "dramatic": ["dramatik olarak", "Ã§arpÄ±cÄ± ÅŸekilde", "gÃ¶zle gÃ¶rÃ¼lÃ¼r biÃ§imde", "belirgin ÅŸekilde"],
        "significant": ["Ã¶nemli Ã¶lÃ§Ã¼de", "kayda deÄŸer ÅŸekilde", "dikkat Ã§ekici biÃ§imde", "gÃ¶rÃ¼nÃ¼r ÅŸekilde"],
        "moderate": ["orta dÃ¼zeyde", "makul Ã¶lÃ§Ã¼de", "Ä±lÄ±mlÄ± ÅŸekilde", "orta seviyede"],
        "slight": ["hafifÃ§e", "kÃ¼Ã§Ã¼k Ã¶lÃ§Ã¼de", "az miktarda", "minimal ÅŸekilde"]
    },
    "comparison_phrases": {
        "highest": ["en yÃ¼ksek", "maksimum", "tepe noktasÄ±", "zirve", "en Ã¼st seviye"],
        "lowest": ["en dÃ¼ÅŸÃ¼k", "minimum", "dip noktasÄ±", "en alt seviye", "asgari"],
        "similar": ["benzer", "yakÄ±n", "eÅŸdeÄŸer", "karÅŸÄ±laÅŸtÄ±rÄ±labilir", "aynÄ± dÃ¼zeyde"],
        "different": ["farklÄ±", "ayrÄ±", "deÄŸiÅŸik", "baÅŸka", "diÄŸer"]
    },
    "time_expressions": {
        "period": ["dÃ¶nem", "sÃ¼reÃ§", "zaman dilimi", "periyot", "ara"],
        "beginning": ["baÅŸlangÄ±Ã§ta", "ilk olarak", "Ã¶nce", "baÅŸta", "ilk dÃ¶nemde"],
        "end": ["sonunda", "nihayetinde", "son dÃ¶nemde", "bitiminde", "tamamÄ±nda"],
        "throughout": ["boyunca", "sÃ¼resince", "tÃ¼m dÃ¶nemde", "genelinde", "sÃ¼rekli"]
    }
}

def call_ollama_for_analysis(table_data: List[Dict], language: str) -> TableAnalysis:
    """Ollama LLM'den tablo analizi al"""
    try:
        # Tabloyu string'e Ã§evir
        table_str = json.dumps(table_data, ensure_ascii=False, indent=2)
        
        # DetaylÄ± analiz prompt'u oluÅŸtur
        prompt = create_detailed_analysis_prompt(table_str, language)
        
        url = f"{OLLAMA_BASE_URL}/api/generate"
        payload = {
            "model": MODEL_NAME,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 2000
            }
        }
        
        response = requests.post(url, json=payload, timeout=120)
        response.raise_for_status()
        
        result = response.json()
        llm_response = result.get("response", "")
        
        # JSON parse et
        if "```json" in llm_response:
            json_start = llm_response.find("```json") + 7
            json_end = llm_response.find("```", json_start)
            json_str = llm_response[json_start:json_end].strip()
        else:
            json_str = llm_response.strip()
        
        data = json.loads(json_str)
        
        return TableAnalysis(
            title=data.get("title", "DetaylÄ± Tablo Analizi"),
            executive_summary=data.get("executive_summary", ""),
            key_insights=data.get("key_insights", []),
            statistical_analysis=data.get("statistical_analysis", ""),
            trend_analysis=data.get("trend_analysis", ""),
            comparative_analysis=data.get("comparative_analysis", ""),
            correlation_analysis=data.get("correlation_analysis", ""),
            anomaly_detection=data.get("anomaly_detection", ""),
            business_implications=data.get("business_implications", ""),
            strategic_recommendations=data.get("strategic_recommendations", []),
            risk_assessment=data.get("risk_assessment", ""),
            future_projection=data.get("future_projection", ""),
            detailed_analysis=data.get("detailed_analysis", "")
        )
        
    except Exception as e:
        print(f"âŒ LLM analiz hatasÄ±: {e}")
        # Fallback analiz
        return create_fallback_analysis(table_data)

def create_detailed_analysis_prompt(table_str: str, language: str) -> str:
    """DetaylÄ± analiz iÃ§in prompt oluÅŸtur - Ufuk aÃ§Ä±cÄ± bilgilerle"""
    vocab = TURKISH_VOCABULARY if language == "turkish" else {}
    
    return f"""
    Bu tabloyu derinlemesine analiz et ve kullanÄ±cÄ±ya ufuk aÃ§Ä±cÄ± bilgiler sun. Sadece yÃ¼zeysel analiz deÄŸil, verilerin arkasÄ±ndaki hikayeyi, gizli kalÄ±plarÄ±, beklenmeyen iliÅŸkileri ve stratejik fÄ±rsatlarÄ± ortaya Ã§Ä±kar.
    
    Tablo Verisi:
    {table_str}
    
    Analiz yaparken ÅŸu unsurlarÄ± kullan:
    - Trend fiilleri: {', '.join(vocab.get('trend_verbs', {}).get('increase', []))} gibi
    - YoÄŸunluk zarflarÄ±: {', '.join(vocab.get('intensity_adverbs', {}).get('significant', []))} gibi
    - KarÅŸÄ±laÅŸtÄ±rma ifadeleri: {', '.join(vocab.get('comparison_phrases', {}).get('highest', []))} gibi
    - Zaman ifadeleri: {', '.join(vocab.get('time_expressions', {}).get('period', []))} gibi
    
    JSON formatÄ±nda yanÄ±t ver:
    {{
        "title": "Ã‡arpÄ±cÄ± ve dikkat Ã§ekici baÅŸlÄ±k",
        "executive_summary": "YÃ¶netici Ã¶zeti - 3-4 cÃ¼mle ile ana bulgular",
        "key_insights": ["Gizli kalÄ±p 1", "Beklenmeyen bulgu 2", "Stratejik fÄ±rsat 3", "Risk sinyali 4"],
        "statistical_analysis": "Ä°statistiksel analiz - ortalama, standart sapma, varyans, korelasyonlar",
        "trend_analysis": "Trend analizi - mevsimsellik, dÃ¶ngÃ¼sel kalÄ±plar, yapÄ±sal deÄŸiÅŸimler",
        "comparative_analysis": "KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz - performans farklarÄ±, rekabet analizi",
        "correlation_analysis": "Korelasyon analizi - deÄŸiÅŸkenler arasÄ± iliÅŸkiler, nedensellik",
        "anomaly_detection": "Anomali tespiti - aykÄ±rÄ± deÄŸerler, beklenmeyen deÄŸiÅŸimler",
        "business_implications": "Ä°ÅŸ etkileri - operasyonel, finansal, stratejik sonuÃ§lar",
        "strategic_recommendations": ["Aksiyon Ã¶nerisi 1", "Stratejik Ã¶neri 2", "Risk yÃ¶netimi 3"],
        "risk_assessment": "Risk deÄŸerlendirmesi - potansiyel tehditler, fÄ±rsatlar",
        "future_projection": "Gelecek projeksiyonu - trend devamÄ±, senaryo analizi",
        "detailed_analysis": "DetaylÄ± analiz - tÃ¼m bulgularÄ±n derinlemesine aÃ§Ä±klamasÄ±"
    }}
    """


def create_fallback_analysis(table_data: List[Dict]) -> TableAnalysis:
    """LLM baÅŸarÄ±sÄ±z olursa basit analiz oluÅŸtur"""
    df = pd.DataFrame(table_data)
    
    return TableAnalysis(
        title="DetaylÄ± Tablo Analizi",
        executive_summary=f"Tablo {len(table_data)} satÄ±r ve {len(df.columns)} sÃ¼tun iÃ§eriyor.",
        key_insights=[
            f"Toplam {len(table_data)} veri noktasÄ±",
            f"{len(df.columns)} farklÄ± sÃ¼tun",
            "Veri analizi tamamlandÄ±"
        ],
        statistical_analysis="Ä°statistiksel analiz yapÄ±lamadÄ±",
        trend_analysis="Trend analizi yapÄ±lamadÄ±",
        comparative_analysis="KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz yapÄ±lamadÄ±",
        correlation_analysis="Korelasyon analizi yapÄ±lamadÄ±",
        anomaly_detection="Anomali tespiti yapÄ±lamadÄ±",
        business_implications="Ä°ÅŸ etkileri deÄŸerlendirilemedi",
        strategic_recommendations=["Daha detaylÄ± analiz Ã¶nerilir"],
        risk_assessment="Risk deÄŸerlendirmesi yapÄ±lamadÄ±",
        future_projection="Gelecek projeksiyonu yapÄ±lamadÄ±",
        detailed_analysis="Basit analiz tamamlandÄ±."
    )

def parse_csv_file(file_content: bytes) -> List[Dict]:
    """CSV dosyasÄ±nÄ± parse et"""
    try:
        df = pd.read_csv(io.StringIO(file_content.decode('utf-8')))
        return df.to_dict('records')
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"CSV parse hatasÄ±: {str(e)}")

def parse_excel_file(file_content: bytes, sheet_name: str = None) -> List[Dict]:
    """Excel dosyasÄ±nÄ± parse et"""
    try:
        df = pd.read_excel(io.BytesIO(file_content), sheet_name=sheet_name)
        return df.to_dict('records')
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Excel parse hatasÄ±: {str(e)}")

# API Endpoints
@app.get("/health")
async def health_check():
    """SaÄŸlÄ±k kontrolÃ¼"""
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        ollama_status = "healthy" if response.status_code == 200 else "unhealthy"
    except:
        ollama_status = "unhealthy"
    
    return {
        "status": "healthy",
        "service": "table-analyzer",
        "ollama_status": ollama_status,
        "model": MODEL_NAME
    }

@app.post("/analyze-table", response_model=TableAnalysisResponse)
async def analyze_table(request: TableAnalysisRequest):
    """JSON tablosundan detaylÄ± analiz Ã¼ret"""
    try:
        if not request.table_data:
            raise HTTPException(status_code=400, detail="Tablo verisi boÅŸ olamaz")
        
        print(f"ğŸ“Š DetaylÄ± tablo analizi yapÄ±lÄ±yor...")
        
        start_time = time.time()
        
        # LLM ile detaylÄ± analiz
        analysis = call_ollama_for_analysis(
            request.table_data, 
            request.language
        )
        
        processing_time = time.time() - start_time
        
        return TableAnalysisResponse(
            success=True,
            analysis=analysis,
            metadata={
                "analysis_type": "detailed",
                "language": request.language,
                "processing_time": round(processing_time, 2),
                "table_rows": len(request.table_data),
                "model": MODEL_NAME
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Tablo analiz hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload-csv-and-analyze", response_model=TableAnalysisResponse)
async def upload_csv_and_analyze(
    file: UploadFile = File(...),
    language: str = Form("turkish"),
    output_format: str = Form("text")
):
    """CSV dosyasÄ± yÃ¼kle ve detaylÄ± analiz et"""
    try:
        if not file.filename.endswith('.csv'):
            raise HTTPException(status_code=400, detail="Sadece CSV dosyalarÄ± desteklenir")
        
        file_content = await file.read()
        table_data = parse_csv_file(file_content)
        
        # JSON endpoint'ini Ã§aÄŸÄ±r
        request = TableAnalysisRequest(
            table_data=table_data,
            language=language,
            output_format=output_format
        )
        
        return await analyze_table(request)
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ CSV upload hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload-excel-and-analyze", response_model=TableAnalysisResponse)
async def upload_excel_and_analyze(
    file: UploadFile = File(...),
    sheet_name: str = Form(None),
    language: str = Form("turkish"),
    output_format: str = Form("text")
):
    """Excel dosyasÄ± yÃ¼kle ve detaylÄ± analiz et"""
    try:
        if not file.filename.endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="Sadece Excel dosyalarÄ± desteklenir")
        
        file_content = await file.read()
        table_data = parse_excel_file(file_content, sheet_name)
        
        # JSON endpoint'ini Ã§aÄŸÄ±r
        request = TableAnalysisRequest(
            table_data=table_data,
            language=language,
            output_format=output_format
        )
        
        return await analyze_table(request)
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Excel upload hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """Ana sayfa"""
    return {
        "service": "Table Analyzer Service",
        "version": "1.0.0",
        "supported_formats": ["json", "csv", "excel"],
        "analysis_type": "detailed",
        "languages": ["turkish", "english"],
        "endpoints": {
            "analyze_table": "POST /analyze-table",
            "upload_csv": "POST /upload-csv-and-analyze", 
            "upload_excel": "POST /upload-excel-and-analyze",
            "health": "GET /health"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)
