# ğŸƒ Bilgi KartlarÄ± Servisi

Bu servis, kullanÄ±cÄ±nÄ±n girdiÄŸi metinleri analiz ederek bilgi kartlarÄ± Ã¼retir. Ollama LLM modeli ile akÄ±llÄ± iÃ§erik Ã§Ä±karÄ±mÄ± yapar.

## ğŸš€ Ã–zellikler

- **Metin Analizi**: Verilen metni analiz eder
- **Bilgi Ã‡Ä±karÄ±mÄ±**: Metinden Ã¶nemli bilgileri Ã§Ä±karÄ±r
- **Kart Ãœretimi**: Ä°stenen adet kadar bilgi kartÄ± oluÅŸturur
- **Dinamik Ä°Ã§erik**: Her kart benzersiz ve anlamlÄ± iÃ§erik iÃ§erir
- **LLM Entegrasyonu**: Ollama Gemma3:27b modeli kullanÄ±r

## ğŸ› ï¸ Teknik Detaylar

### API Endpoints

#### 1. Bilgi KartlarÄ± Ãœretimi
```http
POST /generate-cards
Content-Type: application/json

{
  "text": "Analiz edilecek metin buraya gelir...",
  "card_count": 5
}
```

**Response:**
```json
{
  "success": true,
  "cards": [
    {
      "id": 1,
      "content": "SÄ±fÄ±r atÄ±k nedir? SÄ±fÄ±r atÄ±k, kaynaklarÄ±n verimli kullanÄ±lmasÄ±...",
      "type": "question_answer"
    },
    {
      "id": 2,
      "content": "Yapay Zeka: Makinelerin insan benzeri dÃ¼ÅŸÃ¼nme...",
      "type": "definition"
    }
  ],
  "metadata": {
    "total_cards": 5,
    "processing_time": 12.5,
    "text_length": 2500,
    "model": "gemma3:27b"
  }
}
```

#### 2. SaÄŸlÄ±k KontrolÃ¼
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "service": "info-cards",
  "ollama_status": "healthy",
  "model": "gemma3:27b"
}
```

## ğŸ“ Dosya YapÄ±sÄ±

```
info-cards/
â”œâ”€â”€ app.py              # Ana FastAPI uygulamasÄ±
â”œâ”€â”€ requirements.txt    # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ Dockerfile         # Container tanÄ±mÄ±
â””â”€â”€ README.md          # Bu dosya
```

## ğŸ¯ KullanÄ±m Ã–rnekleri

### Temel Kart Ãœretimi
```bash
curl -X POST http://localhost:8008/generate-cards \
  -H "Content-Type: application/json" \
  -d '{
    "text": "SÄ±fÄ±r atÄ±k projesi hakkÄ±nda detaylÄ± metin...",
    "card_count": 5
  }'
```

### Python ile KullanÄ±m
```python
import requests

response = requests.post('http://localhost:8008/generate-cards', 
    json={
        'text': 'Yapay zeka teknolojileri hakkÄ±nda metin...',
        'card_count': 3
    }
)

result = response.json()
for card in result['cards']:
    print(f"Kart {card['id']}: {card['content']}")
```

## ğŸ”§ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### Docker Compose ile (Ã–nerilen)
```bash
# Projeyi klonlayÄ±n
git clone https://github.com/aeyeniay/ai_hub.git
cd ai_hub

# .env dosyasÄ±nÄ± oluÅŸturun
./setup.sh

# Ollama modellerini indirin
ollama pull gemma3:27b

# Servisi build edin ve baÅŸlatÄ±n
sudo docker compose build info-cards
sudo docker compose up info-cards -d
```

### Yerel GeliÅŸtirme
```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# UygulamayÄ± Ã§alÄ±ÅŸtÄ±r
python app.py
```

## ğŸ› Sorun Giderme

### Ollama BaÄŸlantÄ± HatasÄ±
- `OLLAMA_BASE_URL` ortam deÄŸiÅŸkenini kontrol edin
- Ollama servisinin host'ta Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun
- `sudo systemctl restart ollama` komutunu deneyin

### Model YÃ¼kleme HatasÄ±
```bash
# Ollama modelini kontrol et
ollama list

# Modeli indir
ollama pull gemma3:27b
```

## ğŸ“Š Performans

### Ä°ÅŸlem SÃ¼releri
- **Kart Ãœretimi**: ~10-20 saniye (LLM yanÄ±t sÃ¼resine baÄŸlÄ±)
- **Metin Analizi**: ~5-10 saniye

### Memory KullanÄ±mÄ±
- **Temel iÅŸlem**: ~100-200MB (Python ve FastAPI)
- **LLM kullanÄ±mÄ±**: Ollama modelinin RAM ihtiyacÄ±na gÃ¶re deÄŸiÅŸir (Gemma3:27b iÃ§in ~20GB)

## ğŸ”® Gelecek Ã–zellikler

- [ ] FarklÄ± LLM modelleri iÃ§in destek
- [ ] Kart export seÃ§enekleri (PDF, CSV)
- [ ] Kart kategorileri ve filtreleme
- [ ] Web arayÃ¼zÃ¼ ile kart gÃ¶rÃ¼ntÃ¼leme

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun
3. DeÄŸiÅŸikliklerinizi commit edin
4. Pull request gÃ¶nderin
