# AI Hub Services

Bu proje, gÃ¶rsel Ã¼retim, gÃ¶rselden soru-cevap ve nesne tespiti servislerini iÃ§eren bir AI hub'Ä±dÄ±r.

## ğŸš€ Servisler

- **imggen** (Port 8001): SDXL-Turbo ile gÃ¶rsel Ã¼retim
- **vqa** (Port 8002): Ollama VLM ile gÃ¶rselden soru-cevap  
- **detect** (Port 8000): **LLaVA-34B ile nesne tespiti** ğŸ†•
- **nginx** (Port 80): Reverse proxy

## âš ï¸ Ã–nemli Notlar

### Ollama EriÅŸimi
- VQA ve Detect servisleri Ollama'ya eriÅŸmek iÃ§in `network_mode: "host"` kullanÄ±r
- Ollama host'ta Ã§alÄ±ÅŸmalÄ± (127.0.0.1:11434)
- Container'da `host.docker.internal` Ã§alÄ±ÅŸmaz (sadece Mac/Win Docker Desktop)

### GPU Gereksinimleri
- **imggen**: GPU hÄ±zlandÄ±rma ister (CUDA 12.1)
- **detect**: **GPU gerekmez** - LLaVA Ollama Ã¼zerinden Ã§alÄ±ÅŸÄ±r ğŸ†•
- **vqa**: GPU gerekmez - Ollama Ã¼zerinden Ã§alÄ±ÅŸÄ±r

## ğŸ› ï¸ Kurulum

### 1. Ollama Kurulumu (Host)
```bash
# Ollama'Ä± host'ta kur ve Ã§alÄ±ÅŸtÄ±r
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve

# LLaVA-34B modelini indir (nesne tespiti iÃ§in)
ollama pull llava:34b

# LLaVA modelini indir (VQA iÃ§in)
ollama pull llava
```

### 2. NVIDIA Docker Kurulumu (sadece imggen iÃ§in)
```bash
# NVIDIA Container Toolkit kur
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### 3. Servisleri BaÅŸlat
```bash
# TÃ¼m servisleri build et ve baÅŸlat
docker-compose up --build

# Arka planda Ã§alÄ±ÅŸtÄ±r
docker-compose up -d --build
```

## ğŸ“ Dizin YapÄ±sÄ±

```
ai-hub-services/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ imggen/          # GÃ¶rsel Ã¼retim servisi (GPU gerekli)
â”‚   â”œâ”€â”€ vqa/            # VQA servisi (Ollama Ã¼zerinden)
â”‚   â””â”€â”€ detect/         # **LLaVA nesne tespiti (Ollama Ã¼zerinden)** ğŸ†•
â”œâ”€â”€ uploads/            # YÃ¼klenen dosyalar
â”œâ”€â”€ outputs/            # Ãœretilen Ã§Ä±ktÄ±lar
â”œâ”€â”€ docker-compose.yml  # Servis konfigÃ¼rasyonu
â””â”€â”€ nginx.conf         # Nginx konfigÃ¼rasyonu
```

## ğŸ”§ API KullanÄ±mÄ±

### GÃ¶rsel Ãœretim (imggen)
```bash
curl -X POST http://localhost:8001/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a beautiful sunset over mountains"}'
```

### GÃ¶rselden Soru-Cevap (vqa)
```bash
curl -X POST http://localhost:8002/vqa \
  -F "image=@image.jpg" \
  -F "question=What do you see in this image?"
```

### **LLaVA Nesne Tespiti (detect)** ğŸ†•
```bash
# Port 8000'de Ã§alÄ±ÅŸÄ±r (host network)
curl -X POST http://localhost:8000/detect \
  -F "image=@image.jpg"
```

**Ã‡Ä±ktÄ± Ã¶rneÄŸi:**
```json
{
  "detections": [
    {
      "name": "araba",
      "location": "gÃ¶rselin sol tarafÄ±nda",
      "details": "kÄ±rmÄ±zÄ± renk, orta boyut",
      "confidence": 95
    },
    {
      "name": "bina",
      "location": "arka planda",
      "details": "yÃ¼ksek, modern mimari",
      "confidence": 88
    }
  ],
  "total_objects": 2,
  "model": "llava:34b"
}
```

## ğŸ› Sorun Giderme

### GPU HatasÄ± (imggen iÃ§in)
```bash
# NVIDIA Docker Ã§alÄ±ÅŸÄ±yor mu kontrol et
docker run --rm --gpus all nvidia/cuda:12.1.1-base-ubuntu22.04 nvidia-smi
```

### Ollama BaÄŸlantÄ± HatasÄ±
```bash
# Ollama host'ta Ã§alÄ±ÅŸÄ±yor mu kontrol et
curl http://127.0.0.1:11434/api/tags

# LLaVA-34B modeli var mÄ± kontrol et
ollama list
```

### Port Ã‡akÄ±ÅŸmasÄ±
```bash
# Hangi portlar kullanÄ±lÄ±yor kontrol et
netstat -tlnp | grep :800
```

## ğŸ“ Notlar

- **detect servisi**: ArtÄ±k LLaVA-34B kullanÄ±r, GPU'ya gerek yok
- **Ã‡evre/Åehircilik**: Binalar, yollar, yeÅŸil alanlar tespit edilebilir
- **TÃ¼rkÃ§e destek**: LLaVA TÃ¼rkÃ§e nesne tespiti yapabilir
- **DetaylÄ± analiz**: Sadece tespit deÄŸil, konum ve detay bilgisi
- **Host network**: Detect ve VQA servisleri host network kullanÄ±r
