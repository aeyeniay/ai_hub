# AI Hub Services

Bu proje, gÃ¶rsel Ã¼retim, nesne tespiti ve gÃ¶rselden soru-cevap servislerini iÃ§eren bir AI hub'Ä±dÄ±r.

## ğŸš€ Servisler

- **imggen** (Port 8001): SDXL-Turbo ile gÃ¶rsel Ã¼retim (GPU hÄ±zlandÄ±rmalÄ±)
- **detect** (Port 8003): Gemma3:27b ile nesne tespiti (Ollama Ã¼zerinden)
- **vqa** (Port 8002): LLaVA:34b ile gÃ¶rselden soru-cevap (Ollama Ã¼zerinden)

## ğŸ–¥ï¸ Sistem Gereksinimleri

### DonanÄ±m
- **GPU**: NVIDIA GPU (CUDA 12.1+ destekli) - ImageGen servisi iÃ§in
- **RAM**: En az 16GB (Ollama modelleri iÃ§in)
- **Disk**: En az 50GB boÅŸ alan (modeller iÃ§in)

### YazÄ±lÄ±m
- **Docker**: 20.10+
- **Docker Compose**: 2.0+
- **NVIDIA Container Toolkit**: GPU desteÄŸi iÃ§in
- **Ollama**: 0.1.0+ (host sistemde)
- **CUDA**: 12.1+ (GPU iÃ§in)

## âš ï¸ Ã–nemli Notlar

### Ollama YÃ¶netimi
- **Kritik**: Ollama servisi bazen yeniden baÅŸlatÄ±lmasÄ± gerekebilir
- Detect servisi timeout verirse: `sudo systemctl restart ollama`
- Ollama host'ta Ã§alÄ±ÅŸmalÄ± (127.0.0.1:11434)
- Container'lar `network_mode: "host"` kullanÄ±r

### GPU KullanÄ±mÄ±
- **imggen**: CUDA GPU hÄ±zlandÄ±rmasÄ± kullanÄ±r
- **detect**: Ollama Ã¼zerinden Ã§alÄ±ÅŸÄ±r (GPU opsiyonel)
- **vqa**: Ollama Ã¼zerinden Ã§alÄ±ÅŸÄ±r (GPU opsiyonel)

## ğŸ› ï¸ Kurulum

### 1. Ollama Kurulumu (Host)
```bash
# Ollama'yÄ± host'ta kur ve Ã§alÄ±ÅŸtÄ±r
curl -fsSL https://ollama.ai/install.sh | sh
sudo systemctl enable ollama
sudo systemctl start ollama

# Gerekli modelleri indir
ollama pull gemma3:27b    # Detect servisi iÃ§in
ollama pull llava:34b     # VQA servisi iÃ§in
```

### 2. NVIDIA Docker Kurulumu
```bash
# NVIDIA Container Toolkit kur
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### 3. Proje Kurulumu
```bash
# Projeyi klonla
git clone <repository-url>
cd ai_hub

# Gerekli dizinleri oluÅŸtur
mkdir -p uploads outputs

# Servisleri baÅŸlat
docker-compose up --build -d
```

## ğŸ“ Dizin YapÄ±sÄ±

```
ai_hub/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ image/           # GÃ¶rsel iÅŸleme servisleri
â”‚   â”‚   â”œâ”€â”€ imggen/      # GÃ¶rsel Ã¼retim servisi (GPU gerekli)
â”‚   â”‚   â”œâ”€â”€ detect/      # Nesne tespiti servisi (Ollama Ã¼zerinden)
â”‚   â”‚   â””â”€â”€ vqa/         # VQA servisi (Ollama Ã¼zerinden)
â”‚   â””â”€â”€ text/            # Metin iÅŸleme servisleri (gelecekte eklenecek)
â”œâ”€â”€ data/                # Merkezi veri yÃ¶netimi
â”‚   â”œâ”€â”€ uploads/         # YÃ¼klenen dosyalar
â”‚   â”‚   â”œâ”€â”€ images/      # GÃ¶rsel dosyalar
â”‚   â”‚   â””â”€â”€ documents/   # Metin dosyalarÄ±
â”‚   â””â”€â”€ outputs/         # Ãœretilen Ã§Ä±ktÄ±lar
â”‚       â”œâ”€â”€ images/      # Ãœretilen gÃ¶rseller
â”‚       â”œâ”€â”€ summaries/   # Ã–zetler
â”‚       â””â”€â”€ translations/# Ã‡eviriler
â”œâ”€â”€ frontend/            # Web arayÃ¼zÃ¼
â”œâ”€â”€ docker-compose.yml   # Servis konfigÃ¼rasyonu
â””â”€â”€ README.md            
```

## ğŸ”§ API KullanÄ±mÄ±

### GÃ¶rsel Ãœretim (imggen)
```bash
curl -X POST http://localhost:8001/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a beautiful sunset over mountains"}'
```

### Nesne Tespiti (detect)
```bash
curl -X POST http://localhost:8003/detect \
  -F "image=@data/uploads/images/deneme2.jpg" \
  -F "confidence=0.3" \
  -F "max_objects=15"
```

**Ã‡Ä±ktÄ± Ã¶rneÄŸi:**
```json
{
  "status": "success",
  "model": "gemma3:27b",
  "total_objects": 10,
  "objects": [
    {
      "name": "araba",
      "confidence": 95,
      "location": "Center",
      "description": "A silver SUV with the trunk open, parked on a grassy hill."
    },
    {
      "name": "erkek",
      "confidence": 90,
      "location": "Left-Center",
      "description": "A man oturuyor at the edge of the open car trunk, giyiyor a jacket and boots."
    }
  ]
}
```

### GÃ¶rselden Soru-Cevap (vqa)
```bash
curl -X POST http://localhost:8002/vqa \
  -F "image=@data/uploads/images/deneme2.jpg" \
  -F "question=What do you see in this image?"
```

## ğŸ”„ Sistem AkÄ±ÅŸ DiyagramÄ±

```mermaid
graph TB
    A[KullanÄ±cÄ±] --> B[API Ä°stekleri]
    
    B --> C[ImageGen Servisi<br/>Port 8001]
    B --> D[Detect Servisi<br/>Port 8003]
    B --> E[VQA Servisi<br/>Port 8002]
    
    C --> F[SDXL-Turbo Model<br/>CUDA GPU]
    F --> G[GÃ¶rsel Ãœretimi<br/>data/outputs/images/]
    
    D --> H[Ollama API<br/>127.0.0.1:11434]
    E --> H
    
    H --> I[Gemma3:27b Model<br/>Nesne Tespiti]
    H --> J[LLaVA:34b Model<br/>GÃ¶rsel Soru-Cevap]
    
    I --> K[TÃ¼rkÃ§e Nesne Analizi<br/>JSON Response Only]
    J --> L[GÃ¶rsel Soru-Cevap<br/>JSON Response Only]
    
    G --> M[KullanÄ±cÄ±ya DÃ¶nen SonuÃ§]
    K --> M
    L --> M
    
    style C fill:#e1f5fe
    style D fill:#f3e5f5
    style E fill:#e8f5e8
    style F fill:#fff3e0
    style H fill:#fce4ec
    style K fill:#f8f9fa
    style L fill:#f8f9fa
```

## ğŸ› Sorun Giderme

### Ollama Timeout HatasÄ±
```bash
# Ollama servisini yeniden baÅŸlat
sudo systemctl restart ollama

# Servis durumunu kontrol et
sudo systemctl status ollama

# Modellerin yÃ¼klÃ¼ olduÄŸunu kontrol et
ollama list
```

### GPU HatasÄ± (imggen iÃ§in)
```bash
# NVIDIA Docker Ã§alÄ±ÅŸÄ±yor mu kontrol et
docker run --rm --gpus all nvidia/cuda:12.1.1-base-ubuntu22.04 nvidia-smi

# GPU kullanÄ±mÄ±nÄ± kontrol et
nvidia-smi
```

### Port Ã‡akÄ±ÅŸmasÄ±
```bash
# Hangi portlar kullanÄ±lÄ±yor kontrol et
netstat -tlnp | grep :800

# Container'larÄ± kontrol et
docker ps
```

### Servis SaÄŸlÄ±k KontrolÃ¼
```bash
# TÃ¼m servislerin saÄŸlÄ±ÄŸÄ±nÄ± kontrol et
curl http://localhost:8001/health  # ImageGen
curl http://localhost:8002/health  # VQA
curl http://localhost:8003/health  # Detect
```

## ğŸ“ Ã–zellikler

- **TÃ¼rkÃ§e Destek**: Detect servisi TÃ¼rkÃ§e nesne tespiti yapar
- **GPU HÄ±zlandÄ±rma**: ImageGen servisi CUDA GPU kullanÄ±r
- **ModÃ¼ler YapÄ±**: Her servis baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸabilir
- **Docker TabanlÄ±**: Kolay kurulum ve daÄŸÄ±tÄ±m
- **RESTful API**: Standart HTTP API'ler
- **Merkezi Dosya YÃ¶netimi**: TÃ¼m dosyalar `data/` klasÃ¶rÃ¼nde organize edilir
- **Temiz Ã‡Ä±ktÄ±lar**: Detect servisi sadece analiz yapar, gereksiz dosya kaydetmez

## ğŸ”§ GeliÅŸtirme

### Yeni Servis Ekleme
1. `services/image/` veya `services/text/` altÄ±nda yeni klasÃ¶r oluÅŸtur
2. `Dockerfile` ve `app.py` ekle
3. `docker-compose.yml`'e servis ekle
4. Gerekli portlarÄ± ayarla
5. `data/uploads/` ve `data/outputs/` altÄ±nda gerekli klasÃ¶rleri oluÅŸtur

### Log KontrolÃ¼
```bash
# TÃ¼m servislerin loglarÄ±nÄ± gÃ¶r
docker-compose logs -f

# Belirli servisin loglarÄ±nÄ± gÃ¶r
docker-compose logs -f imggen
docker-compose logs -f detect
docker-compose logs -f vqa
```

## ğŸ“Š Performans

- **ImageGen**: ~2-5 saniye (GPU'ya baÄŸlÄ±) - GÃ¶rsel Ã¼retir ve kaydeder
- **Detect**: ~3-8 saniye (Ollama'ya baÄŸlÄ±) - Sadece analiz yapar, dosya kaydetmez
- **VQA**: ~5-15 saniye (Ollama'ya baÄŸlÄ±) - Sadece metin cevabÄ± dÃ¶ner

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yap
2. Feature branch oluÅŸtur
3. DeÄŸiÅŸikliklerini commit et
4. Pull request gÃ¶nder

## ğŸš€ Gelecek PlanlarÄ±

### Text Servisleri (YakÄ±nda)
- **Summarizer**: Metin Ã¶zetleme servisi
- **Translator**: Ã‡ok dilli Ã§eviri servisi  
- **Sentiment**: Duygu analizi servisi
- **NER**: AdlandÄ±rÄ±lmÄ±ÅŸ varlÄ±k tanÄ±ma servisi

### Sistem AkÄ±ÅŸ DiyagramÄ± (Text Servisleri)
Text servisleri eklendikten sonra ayrÄ± bir diyagram oluÅŸturulacak.

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.